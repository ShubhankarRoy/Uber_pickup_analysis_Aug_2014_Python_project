{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6d500dd",
   "metadata": {},
   "source": [
    "## UBER PICKUPS IN NYC\n",
    "\n",
    "In this project, we are going to analyse the Uber Pickups in New York City. \n",
    "\n",
    "### ABOUT THE DATASET\n",
    "\n",
    "The dataset provided contains data on over 4.5 million Uber pickups in New York City from April to September 2014, and 14.3 million more Uber pickups from January to June 2015.\n",
    "\n",
    "#### Uber trip data from 2014\n",
    "\n",
    "There are six files of raw data on Uber pickups in New York City from April to September 2014. The files are separated by month and each has the following columns:\n",
    "* **Date/Time** : The date and time of the Uber pickup\n",
    "* **Lat** : The latitude of the Uber pickup\n",
    "* **Lon** : The longitude of the Uber pickup\n",
    "* **Base** : The TLC (Taxi & Limousine Commission) base company code affiliated with the Uber pickup\n",
    "\n",
    "These files are named:\n",
    "\n",
    "* `uber-raw-data-apr14.csv`\n",
    "* `uber-raw-data-aug14.csv`\n",
    "* `uber-raw-data-jul14.csv`\n",
    "* `uber-raw-data-jun14.csv`\n",
    "* `uber-raw-data-may14.csv`\n",
    "* `uber-raw-data-sep14.csv`\n",
    "\n",
    "The `base` codes are for the following Uber bases (In the parentheses, we have code names in German which are used internally by Uber to categorize and manage their various service offerings.) :\n",
    "\n",
    "* **B02512 (Unter):** This corresponds to the Uber service category \"UberX\", which is the basic and most common service offering.\n",
    "* **B02598 (Hinter):** This corresponds to the Uber service category \"UberPOOL\", which allows riders heading in the same direction to share a ride and split the cost.\n",
    "* **B02617 (Weiter):** This corresponds to the Uber service category \"UberXL\", which offers larger vehicles such as SUVs and minivans for accommodating more passengers.\n",
    "* **B02682 (Schmecken):** This corresponds to the Uber service category \"UberSELECT\", which provides premium rides with high-end vehicles.\n",
    "* **B02764 (Danach-NY):** This corresponds to the Uber service category \"UberWAV\", which offers wheelchair-accessible vehicles for riders with accessibility needs.\n",
    "* **B02765 (Grun):** This corresponds to the Uber service category \"UberBLACK\", which provides luxury black car services with professional drivers.\n",
    "* **B02835 (Dreist):** This corresponds to the Uber service category \"UberSUV\", which offers larger luxury vehicles for accommodating more passengers.\n",
    "* **B02836 (Drinnen):** This corresponds to the Uber service category \"UberLUX\", which provides high-end luxury vehicles for a premium ride experience.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc84d57b",
   "metadata": {},
   "source": [
    "### 0. Meeting the library requirements\n",
    "\n",
    "In Jupyter Notebooks, you may encounter situations where you want to suppress warning messages that would normally be displayed. The `warnings` module in Python provides a way to control warning behavior in your code. By calling `filterwarnings('ignore')`, you instruct Python to ignore all warnings and not display them in the output. \n",
    "\n",
    "This can be useful in certain situations where you want to suppress warnings that might be irrelevant or distracting for your specific task. However, it's important to note that ignoring warnings globally can sometimes hide important information about potential issues or bugs in your code. It's generally recommended to use caution when suppressing warnings and consider whether it's necessary for your particular use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be83a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5dba17",
   "metadata": {},
   "source": [
    "Run the following cell to install the required libraries. Let's break down the command and its components:\n",
    "\n",
    "* `!`: The exclamation mark (!) at the beginning of the line indicates that the command should be executed as a shell command, rather than as a Python statement.\n",
    "* `pip3`: pip3 is a package installer for Python 3, used to install Python packages from the Python Package Index (PyPI).\n",
    "* `-q`: The -q flag stands for \"quiet\" and is used to suppress output or progress messages during the installation process. It makes the installation process less verbose.\n",
    "* `install:` This keyword tells pip3 that you want to install packages.\n",
    "* `numpy pandas matplotlib seaborn geopy folium datetime scipy sklearn tensorflow`: These are the names of the packages you want to install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89171aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [15 lines of output]\n",
      "  The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  rather than 'sklearn' for pip commands.\n",
      "  \n",
      "  Here is how to fix this error in the main use cases:\n",
      "  - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "    (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  - if the 'sklearn' package is used by one of your dependencies,\n",
      "    it would be great if you take some time to track which package uses\n",
      "    'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  - as a last resort, set the environment variable\n",
      "    SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \n",
      "  More information is available at\n",
      "  https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip3 -q install numpy pandas matplotlib seaborn geopy folium datetime scipy sklearn tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e48da9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m radians,cos,sin,asin,sqrt\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfolium\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geopy'"
     ]
    }
   ],
   "source": [
    "# Importing the libraries installed\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopy.distance\n",
    "\n",
    "from math import radians,cos,sin,asin,sqrt\n",
    "\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "import datetime\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b07981",
   "metadata": {},
   "source": [
    "### 1. Loading the data\n",
    "\n",
    "Let's pick up the 2014 data for our analysis. We can see that there are 6 files for that. Out of which, we will pick `uber-raw-data-jul14.csv` to begin with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data = pd.read_csv('./data/uber-raw-data-jul14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f89ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 10 elements\n",
    "display(uber_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2594420e",
   "metadata": {},
   "source": [
    "### 2. Pre-processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a90754",
   "metadata": {},
   "source": [
    "Let's first see the information about the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6542ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(uber_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcfdc7d",
   "metadata": {},
   "source": [
    "#### 1. Change the type of the data in a column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f746f1",
   "metadata": {},
   "source": [
    "Column `Date/Time` shows the data type as object. To find which object is that, we print the type of data in the first cell of the `Date/Time` column. On doing that, we come to know - it's of string type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb82e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the type of data in Date/Time \n",
    "print(type(uber_data.loc[0,'Date/Time']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f92738",
   "metadata": {},
   "source": [
    "Let's convert it to datetime format for easy indexing. \n",
    "\n",
    "* `pd.to_datetime():` This is a pandas function that converts a given input into a datetime object. It is used here to convert the values of the 'Date/Time' column to datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3482fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data['Date/Time'] = pd.to_datetime(uber_data['Date/Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099491a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the type of data in Date/Time \n",
    "print(type(uber_data.loc[0,'Date/Time']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f2a61",
   "metadata": {},
   "source": [
    "#### 2. Dividing the data in bins\n",
    "\n",
    "Let us divide each hour in existing Date/Time column into four smaller bins of 15 mins each: [0 mins - 15 mins], [15 mins - 30 mins], [30 mins - 45 mins] and [45 mins - 60 mins]. The purpose of binning the time values in this way could be to aggregate or group the data based on time intervals, allowing for analysis at a coarser level of granularity. This can be useful when analyzing patterns or trends that occur within specific time intervals. This will allow us to visualize the data more precisely.\n",
    "\n",
    "* `uber_data['Date/Time']`: This accesses the 'Date/Time' column in the uber_data DataFrame.\n",
    "* `.dt.floor('15min'):` This is a pandas datetime accessor (dt) method that performs floor division to round down the time values to the nearest 15-minute interval. The '15min' argument specifies the desired time interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b0da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to store this new binned column\n",
    "uber_data['BinnedHour'] = uber_data['Date/Time'].dt.floor('15min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37cf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the new column - BinnedHour\n",
    "display(uber_data['BinnedHour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d0171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(uber_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d417a930",
   "metadata": {},
   "source": [
    "### 3. Visualising the data\n",
    "\n",
    "#### 1. Let us visualize the total uber rides per day in the month of July 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da469265",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "uber_data['BinnedHour'].dt.day.value_counts().sort_index().plot(kind='bar', color='green')\n",
    "for item in plt.gca().get_xticklabels():\n",
    "    item.set_rotation(45)\n",
    "plt.title('Uber Rides per day in July 2014 at NYC')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Rides')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bed3a5",
   "metadata": {},
   "source": [
    "Let's understand what's happening here.\n",
    "\n",
    "The first line, `plt.figure(figsize=(14,7))`, creates a new figure object with a specific size of 14 inches in width and 7 inches in height. This sets the dimensions of the plot that will be created.\n",
    "\n",
    "The next line, `uber_data['BinnedHour'].dt.day.value_counts().sort_index().plot(kind='bar',color='green')`, generates the bar chart using the 'BinnedHour' column. It performs several operations in sequence:\n",
    "* `.dt.day:` The .dt accessor allows access to datetime properties, and .day extracts the day component from the 'BinnedHour' column, considering the binned time values.\n",
    "* `.value_counts():` This method counts the occurrences of each unique day in the 'BinnedHour' column, providing a count for the number of rides on each day.\n",
    "* `.sort_index():` This sorts the index (day values) in ascending order.\n",
    "* `.plot(kind='bar', color='green'):` This plots the sorted counts as a bar chart, with each bar representing a day. The kind='bar' parameter specifies the type of plot, and color='green' sets the color of the bars to green.\n",
    "\n",
    "Then the lines `for item in plt.gca().get_xticklabels(): item.set_rotation(45)` rotate the x-axis tick labels by 45 degrees to improve readability. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd5c163",
   "metadata": {},
   "source": [
    "#### Observation 1: There is a recurring pattern in the data! The frequency of trips increases and then decreases in a repeating pattern. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a935750",
   "metadata": {},
   "source": [
    "#### 2. Let us have a more closer look at it, say every 15 minutes from July 1 to July 31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d51f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "uber_data['BinnedHour'].value_counts().sort_index().plot(c='darkblue', alpha=0.8)\n",
    "plt.title('Uber Rides every 15 mins in the month of July at NYC')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('No. of Rides')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11519b",
   "metadata": {},
   "source": [
    "#### Observation 2: The underlying trend is clearly visible now. It conveys that in a day there are times when the pickups are very low and very high, and they seem to follow a pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8196fd",
   "metadata": {},
   "source": [
    "#### Q. Which times correspond to the highest and lowest peaks in the plot above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c15db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(uber_data['BinnedHour'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b65eb",
   "metadata": {},
   "source": [
    "#### Ans. \n",
    "\n",
    "The highest peak corresponds to the time 19:15 (7:15 PM), 15th July 2014 and has a ride count of 915 and the lowest peak corresponds to the time 02:30, 7th July 2014 and has a ride count of 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff0f6b",
   "metadata": {},
   "source": [
    "#### 3. Lets visualize the week wise trends in the data. \n",
    "\n",
    "For this, we will have to map each date into its day name using a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e67650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a dictionary to map the weekday to day name\n",
    "DayMap = {0:'Monday', 1:'Tuesday', 2:'Wednesday', 3:'Thursday', 4:'Friday', 5:'Saturday', 6:'Sunday'}\n",
    "uber_data['Day'] = uber_data['BinnedHour'].dt.weekday.map(DayMap)\n",
    "display(uber_data['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27852abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the date and time to other columns\n",
    "uber_data['Date'] = uber_data['BinnedHour'].dt.date\n",
    "uber_data['Time'] = uber_data['BinnedHour'].dt.time\n",
    "display(uber_data[['Date', 'Time']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4944465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining ordered category of week days for easy sorting and visualization\n",
    "uber_data['Day'] = pd.Categorical(uber_data['Day'], \n",
    "                                  categories=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'],\n",
    "                                  ordered=True)\n",
    "display(uber_data['Day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc7c34e",
   "metadata": {},
   "source": [
    "We now rearrange the dataset a bit for weekly analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef210f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_data = uber_data.groupby(['Date','Day','Time']).count().dropna()\\\n",
    "                .rename(columns={'BinnedHour':'Rides'})['Rides'].reset_index()\n",
    "weekly_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f51f97",
   "metadata": {},
   "source": [
    "We now group weekly data by days to plot total rides per week in July 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ebb22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the weekly_data daywise\n",
    "daywise = weekly_data.groupby('Day').sum()\n",
    "display(daywise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f84b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the graphs for a better visualization\n",
    "sns.set_style(\"dark\")\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# Creating a customized color palette for custom hue according to height of bars\n",
    "vals = daywise.to_numpy().ravel()\n",
    "normalized = (vals - np.min(vals)) / (np.max(vals) - np.min(vals))\n",
    "indices = np.round(normalized * (len(vals) - 1)).astype(np.int32)\n",
    "palette = sns.color_palette('Reds', len(vals))\n",
    "colorPal = np.array(palette).take(indices, axis=0)\n",
    "\n",
    "# Creating a bar plot\n",
    "    ax = sns.barplot(x = daywise.index,y= vals,palette=colorPal)\n",
    "plt.ylabel('Total rides')\n",
    "plt.title('Total Rides by week day in July 2014 at NYC')\n",
    "for rect in ax.patches:\n",
    "    ax.text(rect.get_x() + rect.get_width()/2.0,rect.get_height(),int(rect.get_height()), ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d62cd8",
   "metadata": {},
   "source": [
    "#### Observation 3: According to the bar plot above, rides are maximum on Thursdays and minimum on Sundays. Sundays having the lowest number of rides makes sense logically, as it's a holiday and people often take rest on that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfac3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_data = weekly_data.groupby(['Day','Time']).mean()['Rides']\n",
    "display(weekly_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f10954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstacking the data to create heatmap\n",
    "weekly_data= weekly_data.unstack(level=0)\n",
    "display(weekly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216df243",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,16))\n",
    "sns.heatmap(weekly_data, cmap='Greens')\n",
    "plt.title('Heatmap of average rides in time vs. day grid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc00f905",
   "metadata": {},
   "source": [
    "Here's another way to look at it using line graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad83351",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "weekly_data.plot(ax=plt.gca())\n",
    "plt.title('Average rides per day vs time')\n",
    "plt.ylabel('Average rides')\n",
    "plt.locator_params(axis='x', nbins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b3ddeb",
   "metadata": {},
   "source": [
    "We can also plot the average rides on any day as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c888df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "weekly_data.T.mean().plot(c = 'black')\n",
    "plt.title('Average uber rides on any day in July 2014 at NYC')\n",
    "plt.locator_params(axis='x', nbins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b065579",
   "metadata": {},
   "source": [
    "#### Observation 4: This plot further confirms that the average rides on any given day is lowest around 2 AM and highest in the around 5:30 PM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26433af8",
   "metadata": {},
   "source": [
    "#### 4. Let's visualise the relationship between Base and total number of rides in July 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0527668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A mapper to map base number with its name\n",
    "BaseMapper = {'B02512' : 'Unter', 'B02598' : 'Hinter', 'B02617' : 'Weiter', 'B02682' : 'Schmecken',\n",
    "              'B02764' : 'Danach-NY'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e491b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count plot of Base\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.set_style(\"dark\")\n",
    "sns.countplot(x=uber_data['Base'].map(BaseMapper))\n",
    "plt.ylabel('Total rides')\n",
    "plt.title('CountPlot: Total uber rides vs Base - July 2014, NYC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a918ade6",
   "metadata": {},
   "source": [
    "#### Observation 5: The above plot tells us that most uber rides originated from Weiter Base and least from Danach-NY. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75e0fa4",
   "metadata": {},
   "source": [
    "#### 5. Now let's make use of latitude and longitude data to see how the uber trips' frequency is distributed across NYC. \n",
    "\n",
    "We will need some center of city to act as origin and we will plot the rest of the coordinates around it. \n",
    "\n",
    "For the example given below, we consider the center as Metropolitan Museum in NYC, whose coordinates are `metro_art_coordinates = (40.7794,-73.9632)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf3a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_art_coordinates = (40.7794,-73.9632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f45be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilize the map around NYC and set the zoom level to 10\n",
    "uber_map = folium.Map(location=metro_art_coordinates, zoom_start=10)\n",
    "\n",
    "# Lets mark MM on the map\n",
    "folium.Marker(metro_art_coordinates, popup = \"Metropolitan Museum\").add_to(uber_map)\n",
    "\n",
    "# Convert to numpy array and plot it\n",
    "Lat_Lon = uber_data[['Lat','Lon']].to_numpy()\n",
    "folium.plugins.HeatMap(Lat_Lon,radius=10).add_to(uber_map)\n",
    "\n",
    "# Displaying the map\n",
    "display(uber_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbab356e",
   "metadata": {},
   "source": [
    "We can observe that the boundaries and the intensity distribution of the heatmap on the map is not clear. To fix this, we reduce the intensity of each point on the heatmap by using a weight of 0.5 (by default it is 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b4ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data['Weight'] = 0.5\n",
    "\n",
    "Lat_Lon = uber_data[['Lat','Lon','Weight']].to_numpy()\n",
    "\n",
    "# Plotting\n",
    "uber_map = folium.Map(metro_art_coordinates, zoom_start=10)\n",
    "folium.Marker(metro_art_coordinates, popup = \"Metropolitan Museum\").add_to(uber_map)\n",
    "folium.plugins.HeatMap(Lat_Lon, radius=15).add_to(uber_map)\n",
    "\n",
    "display(uber_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f921e5f7",
   "metadata": {},
   "source": [
    "#### 6. Let's visualize the timed data of trips, as a time lapse on a map! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the data\n",
    "map_data = uber_data.copy()\n",
    "\n",
    "# Use a smaller weight\n",
    "map_data['Weight'] = 0.4\n",
    "\n",
    "# Generate samples for each timestamp in \"BinnedHour\" (these are the points that are plotted for each timestamp)\n",
    "map_data = map_data.groupby(\"BinnedHour\").apply(lambda x: x[['Lat','Lon','Weight']]\n",
    "                                                .sample(int(len(x)/3)).to_numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171c5ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(map_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b718f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index to be passed on to heatmapwithtime needs to be a time series of the following format\n",
    "data_hour_index = [x.strftime(\"%m%d%Y, %H:%M:%S\") for x in map_data.index]\n",
    "\n",
    "# Convert to list to feed it to heatmapwithtime\n",
    "date_hour_data = map_data.tolist()\n",
    "\n",
    "# Initialize map\n",
    "uber_map = folium.Map(location=metro_art_coordinates, zoom_start=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a0ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "hm = folium.plugins.HeatMapWithTime(date_hour_data, index=date_hour_data)\n",
    "\n",
    "# Add heatmap to folium map (uber_map)\n",
    "hm.add_to(uber_map)\n",
    "display(uber_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b95e1b",
   "metadata": {},
   "source": [
    "#### 7. Finally, let's make one hypothesis and test if it is true by visualizing the data for that case. \n",
    "\n",
    "**Hypothesis:** In early morning, weekends have more rides. The reasoning is - People often go out at night during the weekends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a39c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekends = weekly_data[['Saturday','Sunday']]\n",
    "weekdays = weekly_data.drop(['Saturday','Sunday'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd3ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekends = weekends.mean(axis=1)\n",
    "weekdays = weekdays.mean(axis=1)\n",
    "\n",
    "display(weekends)\n",
    "display(weekdays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b713ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays_weekends = pd.concat([weekdays,weekends],axis=1)\n",
    "weekdays_weekends.columns = ['Weekdays','Weekends']\n",
    "display(weekdays_weekends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6082153",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "weekdays_weekends.plot(ax=plt.gca())\n",
    "weekly_data.T.mean().plot(ax=plt.gca(),c = 'black',label='Net Average')\n",
    "plt.title('Time Averaged Rides: Weekend, Weekdays, Net Average (Whole July)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c304ec66",
   "metadata": {},
   "source": [
    "#### Observation 6: The plot clearly shows - In early morning, weekends have more rides. This makes sense as people often go out at night during the weekends.\n",
    "\n",
    "The number of rides around 8 AM is less on weekends, but more on weekdays as it is usually the time when people goto work. Also, in the weekends, there is a surge in the number of evening rides as people return from work.\n",
    "\n",
    "**With this, we finish our analysis of our Uber Pickups NYC Data.**\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
